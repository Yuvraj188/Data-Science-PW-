{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de302fdf-eb0f-4b15-9839-f7e513c6cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# The StandardScaler from scikit-learn is a preprocessing step often used in machine learning workflows, including\n",
    "# with models like SGDRegressor. It's used for standardizing features by removing the mean and scaling to unit variance.\n",
    "# When you scale your data using StandardScaler or any other scaling method, it's important to remember how to inverse\n",
    "# transform it back to the original scale, especially when you want to interpret your model's predictions in terms of the original data.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de7a7251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterthemes\n",
      "  Using cached jupyterthemes-0.20.0-py2.py3-none-any.whl (7.0 MB)\n",
      "Requirement already satisfied: jupyter-core in d:\\ana\\lib\\site-packages (from jupyterthemes) (5.3.0)\n",
      "Requirement already satisfied: notebook>=5.6.0 in d:\\ana\\lib\\site-packages (from jupyterthemes) (6.5.4)\n",
      "Requirement already satisfied: ipython>=5.4.1 in d:\\ana\\lib\\site-packages (from jupyterthemes) (8.15.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in d:\\ana\\lib\\site-packages (from jupyterthemes) (3.7.2)\n",
      "Collecting lesscpy>=0.11.2 (from jupyterthemes)\n",
      "  Obtaining dependency information for lesscpy>=0.11.2 from https://files.pythonhosted.org/packages/2a/da/4a20ba69c9c71ce3d522da5a3c617254d1d1430b71f52b7d46dbf2c06b96/lesscpy-0.15.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading lesscpy-0.15.1-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: backcall in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: decorator in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (2.15.1)\n",
      "Requirement already satisfied: stack-data in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (5.7.1)\n",
      "Requirement already satisfied: colorama in d:\\ana\\lib\\site-packages (from ipython>=5.4.1->jupyterthemes) (0.4.6)\n",
      "Requirement already satisfied: ply in d:\\ana\\lib\\site-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\ana\\lib\\site-packages (from matplotlib>=1.4.3->jupyterthemes) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (3.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.3.2)\n",
      "Requirement already satisfied: pyzmq>=17 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (23.2.0)\n",
      "Requirement already satisfied: argon2-cffi in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (7.4.9)\n",
      "Requirement already satisfied: ipython-genutils in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: nbformat in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (5.9.2)\n",
      "Requirement already satisfied: nbconvert>=5 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.5.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (1.5.6)\n",
      "Requirement already satisfied: ipykernel in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (6.25.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.14.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in d:\\ana\\lib\\site-packages (from notebook>=5.6.0->jupyterthemes) (0.5.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\ana\\lib\\site-packages (from jupyter-core->jupyterthemes) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\ana\\lib\\site-packages (from jupyter-core->jupyterthemes) (305.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\ana\\lib\\site-packages (from jedi>=0.16->ipython>=5.4.1->jupyterthemes) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in d:\\ana\\lib\\site-packages (from jupyter-client>=5.3.4->notebook>=5.6.0->jupyterthemes) (0.4)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in d:\\ana\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.23.4)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in d:\\ana\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.2.2)\n",
      "Requirement already satisfied: lxml in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.9.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.12.2)\n",
      "Requirement already satisfied: bleach in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in d:\\ana\\lib\\site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in d:\\ana\\lib\\site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\ana\\lib\\site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (4.17.3)\n",
      "Requirement already satisfied: wcwidth in d:\\ana\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.4.1->jupyterthemes) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ana\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.3->jupyterthemes) (1.16.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in d:\\ana\\lib\\site-packages (from terminado>=0.8.3->notebook>=5.6.0->jupyterthemes) (2.0.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\ana\\lib\\site-packages (from argon2-cffi->notebook>=5.6.0->jupyterthemes) (21.2.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\ana\\lib\\site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\ana\\lib\\site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (1.6.7)\n",
      "Requirement already satisfied: psutil in d:\\ana\\lib\\site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (5.9.0)\n",
      "Requirement already satisfied: executing in d:\\ana\\lib\\site-packages (from stack-data->ipython>=5.4.1->jupyterthemes) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\ana\\lib\\site-packages (from stack-data->ipython>=5.4.1->jupyterthemes) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in d:\\ana\\lib\\site-packages (from stack-data->ipython>=5.4.1->jupyterthemes) (0.2.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\ana\\lib\\site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (0.18.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in d:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (3.5.0)\n",
      "Requirement already satisfied: websocket-client in d:\\ana\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.58.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\ana\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ana\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.4)\n",
      "Requirement already satisfied: webencodings in d:\\ana\\lib\\site-packages (from bleach->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.5.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\ana\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ana\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.2.0)\n",
      "Requirement already satisfied: pycparser in d:\\ana\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (2.21)\n",
      "Using cached lesscpy-0.15.1-py2.py3-none-any.whl (46 kB)\n",
      "Installing collected packages: lesscpy, jupyterthemes\n",
      "Successfully installed jupyterthemes-0.20.0 lesscpy-0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: jupyterthemes\n",
      "Version: 0.20.0\n",
      "Summary: Select and install a Jupyter notebook theme\n",
      "Home-page: https://github.com/dunovank/jupyter-themes\n",
      "Author: dunovank\n",
      "Author-email: dunovank@gmail.com\n",
      "License: MIT\n",
      "Location: D:\\anaco\\Lib\\site-packages\n",
      "Requires: ipython, jupyter-core, lesscpy, matplotlib, notebook\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip show jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509698b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset css and font defaults in:\n",
      "C:\\Users\\Yuvraj Singh Rathore\\.jupyter\\custom &\n",
      "C:\\Users\\Yuvraj Singh Rathore\\AppData\\Roaming\\jupyter\\nbextensions\n"
     ]
    }
   ],
   "source": [
    "!jt -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29adf0f-fc1f-41b7-ae06-23333b0e1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE DATA\n",
    "california_housing = fetch_california_housing()\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61ea4c9-709f-4c46-829f-128a4d41f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d0e432-1fc4-4866-b97a-01d449e98cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#Create an instance of StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7494cf83-bba9-4b3c-b1d7-93c4cf3d16d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!-- batch_size = 20# each batch contain 20 rows of data \\nnum_batches = len(X_train) // batch_size # // This operation divides one number by another and returns the integer part of the result, discarding any fractional part.\\n# in our batch num_Bathces=825\\n# Create  an instance of the SGDRegressor class from sklearn.linear_model\\nsgd_regressor = SGDRegressor(max_iter=1, alpha=0.0001, random_state=42)\\n\\n\\n\\n# This parameter defines the maximum number of iterations (epochs) that the model will undergo. In this case, it\\'s \\n# set to 1. This means that the model will only see each batch of data once during training.\\n# If you have 1000 samples in your dataset and you set batch_size to 100:\\n# It will take 10 iterations (batches) to complete one epoch (1000 samples / 100 batch size = 10 iterations).\\n# Multiple epochs allow the model to learn from the entire dataset multiple times, improving its performance with each pass.\\n# With a small alpha:\\n\\n# The curve might wiggle a lot to fit each point exactly. This could be good for complex patterns in the data, but it might also be too specific to the training data. This can lead to overfitting.\\n# With a large alpha:\\n\\n# The curve might be a simpler, smoother line. It might not fit each point perfectly, but it captures the overall\\n# trend of the data. This helps prevent overfitting and makes the model generalize better to new, unseen data.\\n\\n# \"more complex models might need stronger regularization,\" we mean that these complex models tend to \\n# learn intricate patterns and details from the training data, which can lead to overfitting. To counteract this\\n# tendency, we often need stronger regularization, which translates to a larger alpha value.\\nfor epoch in range(num_batches):\\n# This loop iterates over the number of batches (num_batches) you have defined.\\n# Each iteration represents one \"epoch\" where the model sees the entire dataset in smaller batches.\\n    start_idx = epoch * batch_size\\n    end_idx = (epoch + 1) * batch_size\\n#epoch + 1 is used to calculate the ending index of each batch, ensuring correct and non-overlapping slicing of the\\n    # dataset for training in mini-batch scenarios.\\n\\n    X_batch = X_train[start_idx:end_idx]\\n    y_batch = y_train[start_idx:end_idx]\\n\\n    # Scale the batch\\n    X_batch_scaled = scaler.fit_transform(X_batch)\\n\\n    # Partial fit on the scaled batch\\n    sgd_regressor.partial_fit(X_batch_scaled, y_batch)\\n\\n# If there are remaining samples that don\\'t fit into a full batch\\nif len(X_train) % batch_size != 0:\\n    X_remaining = X_train[num_batches * batch_size:]\\n    # This slices the remaining samples starting from the index where the last full batch ends.\\n    y_remaining = y_train[num_batches * batch_size:]\\n    \\n    X_remaining_scaled = scaler.fit_transform(X_remaining)\\n    \\n    sgd_regressor.partial_fit(X_remaining_scaled, y_remaining)#partial fit remaining batches\\n -->\\n\\n# if you have 1000 training examples and your batch size is 500 then it will take 2 iterations to complete 1 epoch.\\n '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''<!-- batch_size = 20# each batch contain 20 rows of data \n",
    "num_batches = len(X_train) // batch_size # // This operation divides one number by another and returns the integer part of the result, discarding any fractional part.\n",
    "# in our batch num_Bathces=825\n",
    "# Create  an instance of the SGDRegressor class from sklearn.linear_model\n",
    "sgd_regressor = SGDRegressor(max_iter=1, alpha=0.0001, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# This parameter defines the maximum number of iterations (epochs) that the model will undergo. In this case, it's \n",
    "# set to 1. This means that the model will only see each batch of data once during training.\n",
    "# If you have 1000 samples in your dataset and you set batch_size to 100:\n",
    "# It will take 10 iterations (batches) to complete one epoch (1000 samples / 100 batch size = 10 iterations).\n",
    "# Multiple epochs allow the model to learn from the entire dataset multiple times, improving its performance with each pass.\n",
    "# With a small alpha:\n",
    "\n",
    "# The curve might wiggle a lot to fit each point exactly. This could be good for complex patterns in the data, but it might also be too specific to the training data. This can lead to overfitting.\n",
    "# With a large alpha:\n",
    "\n",
    "# The curve might be a simpler, smoother line. It might not fit each point perfectly, but it captures the overall\n",
    "# trend of the data. This helps prevent overfitting and makes the model generalize better to new, unseen data.\n",
    "\n",
    "# \"more complex models might need stronger regularization,\" we mean that these complex models tend to \n",
    "# learn intricate patterns and details from the training data, which can lead to overfitting. To counteract this\n",
    "# tendency, we often need stronger regularization, which translates to a larger alpha value.\n",
    "for epoch in range(num_batches):\n",
    "# This loop iterates over the number of batches (num_batches) you have defined.\n",
    "# Each iteration represents one \"epoch\" where the model sees the entire dataset in smaller batches.\n",
    "    start_idx = epoch * batch_size\n",
    "    end_idx = (epoch + 1) * batch_size\n",
    "#epoch + 1 is used to calculate the ending index of each batch, ensuring correct and non-overlapping slicing of the\n",
    "    # dataset for training in mini-batch scenarios.\n",
    "\n",
    "    X_batch = X_train[start_idx:end_idx]\n",
    "    y_batch = y_train[start_idx:end_idx]\n",
    "\n",
    "    # Scale the batch\n",
    "    X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "\n",
    "    # Partial fit on the scaled batch\n",
    "    sgd_regressor.partial_fit(X_batch_scaled, y_batch)\n",
    "\n",
    "# If there are remaining samples that don't fit into a full batch\n",
    "if len(X_train) % batch_size != 0:\n",
    "    X_remaining = X_train[num_batches * batch_size:]\n",
    "    # This slices the remaining samples starting from the index where the last full batch ends.\n",
    "    y_remaining = y_train[num_batches * batch_size:]\n",
    "    \n",
    "    X_remaining_scaled = scaler.fit_transform(X_remaining)\n",
    "    \n",
    "    sgd_regressor.partial_fit(X_remaining_scaled, y_remaining)#partial fit remaining batches\n",
    " -->\n",
    "\n",
    "# if you have 1000 training examples and your batch size is 500 then it will take 2 iterations to complete 1 epoch.\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06574d7-1a24-424f-be8f-31f7a51d905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.0112121506645142\n",
      "R^2 Score: 0.22832324300618656\n",
      "       Actual  Predicted\n",
      "0     0.47700   0.257650\n",
      "1     0.45800   1.729494\n",
      "2     5.00001   3.130029\n",
      "3     2.18600   2.601453\n",
      "4     2.78000   2.414003\n",
      "...       ...        ...\n",
      "4123  2.63300   1.997936\n",
      "4124  2.66800   2.201621\n",
      "4125  5.00001   4.501551\n",
      "4126  0.72300   1.305187\n",
      "4127  1.51500   1.566215\n",
      "\n",
      "[4128 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train in Batches using partial_fit\n",
    "batch_size = 20\n",
    "num_batches = len(X_train) // batch_size\n",
    "\n",
    "# Create the SGDRegressor\n",
    "sgd_regressor = SGDRegressor(max_iter=1, alpha=0.0001, random_state=42)\n",
    "\n",
    "for epoch in range(num_batches):\n",
    "    start_idx = epoch * batch_size\n",
    "    end_idx = (epoch + 1) * batch_size\n",
    "\n",
    "    X_batch = X_train[start_idx:end_idx]\n",
    "    y_batch = y_train[start_idx:end_idx]\n",
    "\n",
    "    # Scale the batch\n",
    "    X_batch_scaled = scaler.fit_transform(X_batch)\n",
    "\n",
    "    # Partial fit on the scaled batch\n",
    "    sgd_regressor.partial_fit(X_batch_scaled, y_batch)\n",
    "\n",
    "# If there are remaining samples that don't fit into a full batch\n",
    "if len(X_train) % batch_size != 0:\n",
    "    X_remaining = X_train[num_batches * batch_size:]\n",
    "    y_remaining = y_train[num_batches * batch_size:]\n",
    "\n",
    "    # Scale the remaining samples using the already fitted scaler\n",
    "    X_remaining_scaled = scaler.transform(X_remaining)\n",
    "    \n",
    "    # Partial fit on the scaled remaining samples\n",
    "    sgd_regressor.partial_fit(X_remaining_scaled, y_remaining)\n",
    "\n",
    "# Make predictions on the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "predictions = sgd_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Create a DataFrame for predicted and actual values\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# Print the predicted and actual table\n",
    "print(results)\n",
    "\n",
    "# If you want to continue training the same SGDRegressor model after making predictions, you can simply call the \n",
    "# partial_fit method again on new batches of data. This is similar to the initial training process. you can certainly change the batch size when training your model using partial_fit\n",
    "#use library river and vowpal wabbit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
